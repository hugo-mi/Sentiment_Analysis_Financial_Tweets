{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7349637,"sourceType":"datasetVersion","datasetId":4267967},{"sourceId":7349690,"sourceType":"datasetVersion","datasetId":4268010}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-06T16:11:45.016014Z","iopub.execute_input":"2024-01-06T16:11:45.016882Z","iopub.status.idle":"2024-01-06T16:11:45.030855Z","shell.execute_reply.started":"2024-01-06T16:11:45.016847Z","shell.execute_reply":"2024-01-06T16:11:45.029957Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/fin-tweets-training/fin_tweets_dataset (1).csv\n/kaggle/input/fin-tweets-validation/sent_valid.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom transformers import AutoTokenizer\nfrom datasets import Dataset\nimport pandas as pd\ndf_train = pd.read_csv('/kaggle/input/fin-tweets-training/fin_tweets_dataset (1).csv')\ndf_valid = pd.read_csv('/kaggle/input/fin-tweets-validation/sent_valid.csv')\nmodel_name = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ntrain_dataset = Dataset.from_pandas(df_train)\nvalid_dataset = Dataset.from_pandas(df_valid)\n\n# Initialize the tokenizer\n \n# Tokenization function\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n\n# Apply tokenization\ntokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\ntokenized_valid_dataset = valid_dataset.map(tokenize_function, batched=True)\n\n# R","metadata":{"execution":{"iopub.status.busy":"2024-01-06T16:11:48.091785Z","iopub.execute_input":"2024-01-06T16:11:48.092136Z","iopub.status.idle":"2024-01-06T16:11:56.992850Z","shell.execute_reply.started":"2024-01-06T16:11:48.092106Z","shell.execute_reply":"2024-01-06T16:11:56.991849Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8e0068e5bc74ae18bb2f9abedf7e04d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fcf1d39f9314992b60a1d723b817d34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbc55eefc876416cb75cf63f13cd8ac1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f262cd65fa5a4a1dab1017a5aaaf745c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7992271dfed4245ba7fb8111fd69ebf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6748e56e5383442aa1cf31c382b6329b"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n\nnum_labels = 3  # Number of target labels\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    num_train_epochs=8,\n    weight_decay=0.01,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_valid_dataset,\n)\n\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-06T16:12:48.475431Z","iopub.execute_input":"2024-01-06T16:12:48.475807Z","iopub.status.idle":"2024-01-06T16:30:50.337987Z","shell.execute_reply.started":"2024-01-06T16:12:48.475771Z","shell.execute_reply":"2024-01-06T16:30:50.336816Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5ad0d41271941aeb16be92f65cffcb9"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240106_161404-48wnqzj0</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/charafteam/huggingface/runs/48wnqzj0' target=\"_blank\">ancient-armadillo-5</a></strong> to <a href='https://wandb.ai/charafteam/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/charafteam/huggingface' target=\"_blank\">https://wandb.ai/charafteam/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/charafteam/huggingface/runs/48wnqzj0' target=\"_blank\">https://wandb.ai/charafteam/huggingface/runs/48wnqzj0</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='376' max='376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [376/376 16:11, Epoch 8/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.810858</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.606032</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.608758</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.607193</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.667129</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>0.709621</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>0.676072</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>0.696993</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=376, training_loss=0.39285655731850483, metrics={'train_runtime': 1065.5776, 'train_samples_per_second': 11.261, 'train_steps_per_second': 0.353, 'total_flos': 3157361012736000.0, 'train_loss': 0.39285655731850483, 'epoch': 8.0})"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-01-06T16:36:35.549922Z","iopub.execute_input":"2024-01-06T16:36:35.551079Z","iopub.status.idle":"2024-01-06T16:36:35.579747Z","shell.execute_reply.started":"2024-01-06T16:36:35.551038Z","shell.execute_reply":"2024-01-06T16:36:35.578077Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"080a6c28717c42dba354484ca8b70fe9"}},"metadata":{}}]},{"cell_type":"code","source":"model.save_pretrained('./FINBERX')\ntokenizer.save_pretrained('./FINBERX')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-06T16:40:00.776699Z","iopub.execute_input":"2024-01-06T16:40:00.777431Z","iopub.status.idle":"2024-01-06T16:40:01.672731Z","shell.execute_reply.started":"2024-01-06T16:40:00.777394Z","shell.execute_reply":"2024-01-06T16:40:01.671365Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"('./FINBERX/tokenizer_config.json',\n './FINBERX/special_tokens_map.json',\n './FINBERX/vocab.txt',\n './FINBERX/added_tokens.json',\n './FINBERX/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import HfApi, HfFolder, Repository\nimport os\nimport shutil\n\n# Initialize HfApi instance\napi = HfApi()\n\n# Define your Hugging Face username and the name of your repository\nhf_username = \"zcharaf\"  # Replace with your Hugging Face username\nrepo_name = \"FINBERX\"   # Replace with your desired repository name\n\n# Create a new repository on the Hugging Face Hub\nrepo_url = api.create_repo(repo_name, token=HfFolder.get_token(), exist_ok=True)\n\n# Local directories\nsource_dir = './FINBERX'         # The directory where your model files are saved\ntarget_dir = './FINBERX_clone'   # The directory where you want to clone your repository\n\n# Check if target directory exists and if it contains a .git directory\nif os.path.exists(target_dir):\n    if os.path.isdir(os.path.join(target_dir, '.git')):\n        # If it's already a git repo, delete it\n        shutil.rmtree(target_dir)\n\n# Clone the repository\nrepo = Repository(local_dir=target_dir, clone_from=repo_url)\nrepo.git_pull()\n\n# Copy files from the saved model to the cloned repository\nif os.path.exists(source_dir) and os.listdir(source_dir):\n    os.system(f'cp -r {source_dir}/* {target_dir}/')\n    \n    # Commit and push to the repository\n    repo.git_add(auto_lfs_track=True)\n    repo.git_commit(\"First commit with my fine-tuned model\")\n    repo.git_push()\nelse:\n    print(f\"Error: Source directory '{source_dir}' does not exist or is empty.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-06T16:41:19.680751Z","iopub.execute_input":"2024-01-06T16:41:19.681522Z","iopub.status.idle":"2024-01-06T16:41:42.327214Z","shell.execute_reply.started":"2024-01-06T16:41:19.681482Z","shell.execute_reply":"2024-01-06T16:41:42.326136Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\nFor more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n  warnings.warn(warning_message, FutureWarning)\nCloning https://huggingface.co/zcharaf/FINBERX into local empty directory.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Upload file model.safetensors:   0%|          | 1.00/418M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"381fb62dcd45427b9872b011da6467b4"}},"metadata":{}},{"name":"stderr","text":"To https://huggingface.co/zcharaf/FINBERX\n   47678f1..6507b7a  main -> main\n\n","output_type":"stream"}]}]}